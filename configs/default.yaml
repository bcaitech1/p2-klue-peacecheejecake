system: &default_system_config
  device: "cuda:0"
  num_workers: 8


path: &default_path_config
  input: '/opt/ml/input'
  train: '/opt/ml/input/data/train/train.csv'
  test: '/opt/ml/input/data/test/test.csv'
  valid: 
  submit: '/opt/ml/output/submissions'
  checkpoint: '/opt/ml/output/checkpoints'
  logs: '/opt/ml/output/logs'


data: &default_data_config
  num_classes: 42
  dataset_class: BasicDatasetForElectra
  tokenizer_class: ElectraTokenizer
  add_entity_tokens: 
  valid_ratio: 0.0
  upscaling: False
  sampler: 
  batch_size: 128
  num_folds: 5


train: &default_train_config
  experiment_name: marked-entitystart-koelect
  resuming_state: 
    
  lr:
    base: 5.0e-5
    min: 
    scheduler: CosineAnnealingAfterWarmUpScheduler
    warmup_steps: 67
  weight_decay: 1.0e-4
  betas: [0.9, 0.999]
  momentum: 0.9
  nesterov: False
  criterion: CrossEntropyLoss
  optimizer:
    name: AdamW
  
  num_epochs: 1
  valid_iter_limit: 0
  
  valid_min_epoch: 1
  test_min_epoch: 1
  save_min_epoch: 5

  valid_period: 1
  test_period: 0
  save_period: 1

  valid_min_acc: 0
  test_min_acc: 1
  save_min_acc: 0

  #wandb options
  logger: manual ### TODO: manual / wandb / neptune?


model: &default_model_config
  arc: BasicElectraForSequenceClassification
  pretrained_id: monologg/koelectra-base-v3-discriminator
  name: koelectra-base-dis-clf
  last_head_idx: 0

teacher:
  arc:
  state_path: 
